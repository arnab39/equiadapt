{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Equivariant canonicalization for an Invariant Task (Image Classification with ViT-Base)\n",
    "In this notebook, we test whether the group equivariant image canonicalizer can generate a canonical orientation properly for sample images which can be processed by the prediction network. We also visualize the ground truth and predicted class from a prediction network, which is Vision Transformer ([Dosovitskiy et. al, 2020](https://arxiv.org/abs/2010.11929)). Further we consider the group to be $C_4$ which is rotation of 4 discrete rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from equiadapt.images.canonicalization_networks.escnn_networks import ESCNNEquivariantNetwork\n",
    "from equiadapt.images.canonicalization.discrete_group import GroupEquivariantImageCanonicalization\n",
    "from equiadapt.common.basecanonicalization import IdentityCanonicalization\n",
    "from examples.images.classification.inference_utils import GroupInference\n",
    "\n",
    "from examples.images.classification.model_utils import get_prediction_network\n",
    "from examples.images.classification.prepare import STL10DataModule \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHyperparams:\n",
    "    def __init__(self):\n",
    "        self.dataset_name = \"stl10\" # Name of the dataset to use\n",
    "        self.data_path = \"/home/mila/s/siba-smarak.panigrahi/scratch/data/stl10\" # Path to the dataset\n",
    "        self.augment = 1 # Whether to use data augmentation (1) or not (0)\n",
    "        self.num_workers = 4 # Number of workers for data loading\n",
    "        self.batch_size = 64 # Number of samples per batch\n",
    "        \n",
    "dataset_hyperparams = DatasetHyperparams()\n",
    "data = STL10DataModule(hyperparams=dataset_hyperparams)\n",
    "\n",
    "data.setup()\n",
    "train_loader = data.train_dataloader()\n",
    "\n",
    "data.setup(stage=\"test\")\n",
    "test_loader = data.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design canonicalization hyperparams class\n",
    "class CanonicalizationHyperparams:\n",
    "    def __init__(self):\n",
    "        self.canonicalization_type=\"group_equivariant\" # canonicalization type network\n",
    "        self.network_type = \"escnn\" # group equivariant canonicalization\n",
    "        self.resize_shape = 32 # resize shape for the canonicalization network\n",
    "        self.network_hyperparams = {\n",
    "            \"kernel_size\": 7, # Kernel size for the canonization network\n",
    "            \"out_channels\": 64, # Number of output channels for the canonization network\n",
    "            \"num_layers\": 5, # Number of layers in the canonization network\n",
    "            \"group_type\": \"rotation\", # Type of group for the canonization network\n",
    "            \"num_rotations\": 4, # Number of rotations for the canonization network \n",
    "        }\n",
    "        self.beta = 1.0 \n",
    "        self.input_crop_ratio = 0.9\n",
    "        \n",
    "canonicalization_hyperparams = CanonicalizationHyperparams()\n",
    "\n",
    "# get the canonicalization network\n",
    "canonicalization_network = ESCNNEquivariantNetwork(\n",
    "    in_shape=(3, 32, 32),\n",
    "    **canonicalization_hyperparams.network_hyperparams,\n",
    ").to(device)\n",
    "\n",
    "# get canonicalizer\n",
    "canonicalizer = GroupEquivariantImageCanonicalization(\n",
    "    canonicalization_network=canonicalization_network,\n",
    "    canonicalization_hyperparams=CanonicalizationHyperparams(),\n",
    "    in_shape=(3, 224, 224)\n",
    ").to(device)\n",
    "\n",
    "# get the prediction network, which in this case is Vision Transformer\n",
    "prediction_network = get_prediction_network(\n",
    "    architecture = \"vit\", \n",
    "    dataset_name = \"stl10\",\n",
    "    use_pretrained = True,\n",
    "    freeze_encoder = True,\n",
    "    input_shape = (3, 224, 224),\n",
    "    num_classes = 10\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tqdm progress bar\n",
    "optimizer = torch.optim.Adam(prediction_network.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "# finetuning the prediction network for STL10 dataset\n",
    "for epoch in range(epochs):\n",
    "    tqdm_bar = tqdm(enumerate(train_loader), desc=f\"Epoch {epoch}\", total=len(train_loader))\n",
    "    for _, batch in tqdm_bar:\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        batch_size, num_channels, height, width = x.shape\n",
    "        \n",
    "        # get prediction network output\n",
    "        logits = prediction_network(x)\n",
    "            \n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "            \n",
    "        # Get the predictions and calculate the accuracy\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        acc = (preds == y).float().mean()\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # add loss and accuracy to tqdm bar\n",
    "        tqdm_bar.set_postfix(loss=loss.item(), acc=acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceHyperparams:\n",
    "    def __init__(self):\n",
    "        self.group_type = \"rotation\"\n",
    "        self.num_rotations = 4\n",
    "\n",
    "inference_method = GroupInference(\n",
    "            canonicalizer=IdentityCanonicalization(), \n",
    "            prediction_network=prediction_network, \n",
    "            num_classes=10, \n",
    "            inference_hyperparams=InferenceHyperparams(), \n",
    "            in_shape=(3, 224, 224)\n",
    "        )\n",
    "\n",
    "test_tqdm_bar = tqdm(enumerate(test_loader), desc=f\"Testing\", total=len(test_loader))\n",
    "total_acc, total_group_acc = 0, 0\n",
    "for _, batch in test_tqdm_bar:\n",
    "    x, y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    batch_size, num_channels, height, width = x.shape\n",
    "\n",
    "    test_metrics = inference_method.get_inference_metrics(x, y)\n",
    "    \n",
    "    # add test_metrics acc and group_acc to tqdm bar\n",
    "    test_tqdm_bar.set_postfix(acc=test_metrics[\"test/acc\"].item(), group_acc=test_metrics[\"test/group_acc\"].item())\n",
    "    \n",
    "    total_acc += test_metrics[\"test/acc\"].item()\n",
    "    total_group_acc += test_metrics[\"test/group_acc\"].item()\n",
    "    \n",
    "print(f\"Test Accuracy: {total_acc/len(test_loader):.3f}\")\n",
    "print(f\"Test Group Accuracy: {total_group_acc/len(test_loader):.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction network again\n",
    "prediction_network = get_prediction_network(\n",
    "    architecture = \"vit\", \n",
    "    dataset_name = \"stl10\",\n",
    "    use_pretrained = True,\n",
    "    freeze_encoder = True,\n",
    "    input_shape = (3, 224, 224),\n",
    "    num_classes = 10\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tqdm progress bar\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': prediction_network.parameters(), 'lr': 1e-3},\n",
    "        {'params':canonicalizer.parameters(), 'lr': 1e-3},\n",
    "    ],)\n",
    "epochs = 10\n",
    "\n",
    "# finetuning the prediction network with the canonicalizer for STL10 dataset\n",
    "for epoch in range(epochs):\n",
    "    tqdm_bar = tqdm(enumerate(train_loader), desc=f\"Epoch {epoch}\", total=len(train_loader))\n",
    "    for _, batch in tqdm_bar:\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        batch_size, num_channels, height, width = x.shape\n",
    "\n",
    "        # canonicalize the input data\n",
    "        # For the vanilla model, the canonicalization is the identity transformation\n",
    "        x_canonicalized = canonicalizer(x)\n",
    "\n",
    "        # get prediction network output\n",
    "        logits = prediction_network(x_canonicalized)\n",
    "            \n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        loss += 100 * canonicalizer.get_prior_regularization_loss()\n",
    "            \n",
    "        # Get the predictions and calculate the accuracy\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        acc = (preds == y).float().mean()\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # add loss and accuracy to tqdm bar\n",
    "        tqdm_bar.set_postfix(loss=loss.item(), acc=acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InferenceHyperparams:\n",
    "    def __init__(self):\n",
    "        self.group_type = \"rotation\"\n",
    "        self.num_rotations = 4\n",
    "\n",
    "inference_method = GroupInference(\n",
    "            canonicalizer=canonicalizer, \n",
    "            prediction_network=prediction_network, \n",
    "            num_classes=10, \n",
    "            inference_hyperparams=InferenceHyperparams(), \n",
    "            in_shape=(3, 224, 224)\n",
    "        )\n",
    "\n",
    "test_tqdm_bar = tqdm(enumerate(test_loader), desc=f\"Testing\", total=len(test_loader))\n",
    "total_acc, total_group_acc = 0, 0\n",
    "for _, batch in test_tqdm_bar:\n",
    "    x, y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    batch_size, num_channels, height, width = x.shape\n",
    "    print(x.shape)\n",
    "\n",
    "    test_metrics = inference_method.get_inference_metrics(x, y)\n",
    "    \n",
    "    # add test_metrics acc and group_acc to tqdm bar\n",
    "    test_tqdm_bar.set_postfix(acc=test_metrics[\"test/acc\"].item(), group_acc=test_metrics[\"test/group_acc\"].item())\n",
    "    \n",
    "    total_acc += test_metrics[\"test/acc\"].item()\n",
    "    total_group_acc += test_metrics[\"test/group_acc\"].item()\n",
    "    \n",
    "print(f\"Test Accuracy: {total_acc/len(test_loader)}\")\n",
    "print(f\"Test Group Accuracy: {total_group_acc/len(test_loader)}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
